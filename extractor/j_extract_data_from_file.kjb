<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>j_extract_data_from_file</name>
  <description />
  <extended_description />
  <job_version />
  <job_status>0</job_status>
  <directory>/</directory>
  <created_user>-</created_user>
  <created_date>2017/08/17 12:57:55.350</created_date>
  <modified_user>-</modified_user>
  <modified_date>2017/08/17 12:57:55.350</modified_date>
  <parameters>
    <parameter>
      <name>METADATA</name>
      <default_value />
      <description />
    </parameter>
  </parameters>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection />
    <schema />
    <table />
    <size_limit_lines />
    <interval />
    <timeout_days />
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection />
    <schema />
    <table />
    <timeout_days />
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection />
    <schema />
    <table />
    <timeout_days />
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>N</pass_batchid>
  <shared_objects_file />
  <entries>
    <entry>
      <name>START</name>
      <description />
      <type>SPECIAL</type>
      <attributes />
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>48</xloc>
      <yloc>272</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Metadata compare</name>
      <description />
      <type>TRANS</type>
      <attributes />
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/m_metadata_compare.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration />
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
        <parameter>
          <name>METADATA_COLUMNS_FILE</name>
          <stream_name />
          <value>${METADATA_COLUMNS_FILE}</value>
        </parameter>
        <parameter>
          <name>METADATA_QUEUE_COLUMNS_FILE</name>
          <stream_name />
          <value>${METADATA_QUEUE_COLUMNS_FILE}</value>
        </parameter>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>48</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Metadata exists?</name>
      <description />
      <type>FILE_EXISTS</type>
      <attributes />
      <filename>${METADATA_COLUMNS_FILE}</filename>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>272</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Recreate?</name>
      <description />
      <type>SIMPLE_EVAL</type>
      <attributes />
      <valuetype>variable</valuetype>
      <fieldname />
      <variablename>${IS_RECREATE}</variablename>
      <fieldtype>number</fieldtype>
      <mask />
      <comparevalue>1</comparevalue>
      <minvalue />
      <maxvalue />
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>720</xloc>
      <yloc>48</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Update metadata</name>
      <description />
      <type>SHELL</type>
      <attributes />
      <filename />
      <work_directory />
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <set_append_logfile>N</set_append_logfile>
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>mkdir -p ${METADATA_PATH}

cp -rf ${METADATA_QUEUE_PATH}* ${METADATA_PATH}</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>608</xloc>
      <yloc>384</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Set recreate to 0</name>
      <description />
      <type>SET_VARIABLES</type>
      <attributes />
      <replacevars>N</replacevars>
      <filename />
      <file_variable_type>CURRENT_JOB</file_variable_type>
      <fields>
        <field>
          <variable_name>IS_RECREATE</variable_name>
          <variable_value>0</variable_value>
          <variable_type>ROOT_JOB</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>48</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Set recreate to 1</name>
      <description />
      <type>SET_VARIABLES</type>
      <attributes />
      <replacevars>N</replacevars>
      <filename />
      <file_variable_type>CURRENT_JOB</file_variable_type>
      <fields>
        <field>
          <variable_name>IS_RECREATE</variable_name>
          <variable_value>1</variable_value>
          <variable_type>ROOT_JOB</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>384</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Load data</name>
      <description />
      <type>SHELL</type>
      <attributes />
      <filename>${Internal.Job.Filename.Directory}/shell/${TARGET}.sh</filename>
      <work_directory>/tmp_files/</work_directory>
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <set_append_logfile>N</set_append_logfile>
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>N</insertScript>
      <script />
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>496</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Fail loading data</name>
      <description />
      <type>ABORT</type>
      <attributes />
      <message />
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>608</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Extract metadata</name>
      <description />
      <type>SHELL</type>
      <attributes />
      <filename />
      <work_directory />
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <set_append_logfile>N</set_append_logfile>
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>mkdir -p ${METADATA_QUEUE_PATH}
mkdir -p ${RAWFILE_QUEUE_PATH}
mkdir -p ${RAWFILE_QUEUE_SAMPLE_PATH}

error_check(){
	if [ $? -gt 0 ]; then
       	 echo "An error has occurred :_("

		# Remove os arquivos temporários.
		if [ ${DEBUG} = 0 ] ; then
			rm -rf ${RAWFILE_QUEUE_PATH}*
			rm -rf ${METADATA_QUEUE_PATH}*
		fi

		exit 1
	fi
}

# Identifies if the output mode is APPEND.
if [[ ${FILE_OUTPUT_MODE} != "append" ]]; then	
	HAS_RECORD=`head -5 ${RAWFILE_QUEUE_PATH}${SCHEMA_NAME}_${TABLE_NAME}*.csv | wc -l`
else
	FILE_INDEX=0

	for i in `ls ${RAWFILE_QUEUE_PATH}*`
	do
		if [ -f "${i}" ]; then
			# Get samples data to extract metadata. 
			if [ ${FILE_INDEX} = 0 ]; then	
				head -n ${SAMPLE} ${i} > ${RAWFILE_QUEUE_SAMPLE_FILE} 
				error_check
			else
				SAMPLE_FILE_RECORD=`cat ${RAWFILE_QUEUE_SAMPLE_FILE} | wc -l`
			
				if [ ${SAMPLE} -gt ${SAMPLE_FILE_RECORD} ]; then
					  sed '1d' ${i} >> ${RAWFILE_QUEUE_SAMPLE_FILE}	
					  error_check	
				else
					  break
				fi
			fi

			FILE_INDEX=$(( $FILE_INDEX + 1 ))
		fi
	done
	
	HAS_RECORD=`head -5 ${RAWFILE_QUEUE_SAMPLE_FILE} | wc -l`
fi

# Identifies if there are records to process. 
if [ ${HAS_RECORD} -gt 1 ]; then
	echo "Getting data sample of ${SAMPLE} records"
	
	if [[ ${FILE_OUTPUT_MODE} != "append" ]]; then
		head -n ${SAMPLE} ${RAWFILE_QUEUE_FILE} > ${RAWFILE_QUEUE_SAMPLE_FILE} 
		error_check	
	fi

	DIALECT=${TARGET}
	
	if [ ${TARGET} == "spectrum"  ] &amp;&amp;  [ ${HAS_ATHENA} = 1 ]; then
		DIALECT="athena"
	fi 

	echo "Dialect: " $DIALECT

	echo "Extracting metadata"
	java -jar ${GLOVE_HOME}/extractor/lib/metadata.jar \
		--folder=${RAWFILE_QUEUE_SAMPLE_PATH} \
		--output=${METADATA_QUEUE_PATH} \
		--metadata="${METADATA}" \
		--sample=${SAMPLE} \
		--field="" \
		--delimiter="${DELIMITER}" \
		--escape='${QUOTE_ESCAPE}' \
		--filename=${SCHEMA_NAME}_${TABLE_NAME}.csv  \
		--dialect=${DIALECT} \
		--reservedWords=${RESERVED_WORDS_FILE}
	error_check

	echo "INFERRED METADATA"
	cat ${METADATA_QUEUE_METADATA_FILE}

	rm -rf  ${RAWFILE_QUEUE_SAMPLE_PATH}
	error_check
else
	echo "Nothing to load from ${RAWFILE_QUEUE_PATH}!"
	exit 1
fi</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>272</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Recreate? </name>
      <description />
      <type>SIMPLE_EVAL</type>
      <attributes />
      <valuetype>variable</valuetype>
      <fieldname />
      <variablename>${IS_RECREATE}</variablename>
      <fieldtype>number</fieldtype>
      <mask />
      <comparevalue>1</comparevalue>
      <minvalue />
      <maxvalue />
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>160</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Recreate log</name>
      <description />
      <type>WRITE_TO_LOG</type>
      <attributes />
      <logmessage>Table will be recreated!</logmessage>
      <loglevel>Basic</loglevel>
      <logsubject>RECREATE</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>608</xloc>
      <yloc>160</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Metadata log</name>
      <description />
      <type>WRITE_TO_LOG</type>
      <attributes />
      <logmessage>Metadata was not extracted!
Check if query returned at least one record or if happened error on the process.</logmessage>
      <loglevel>Basic</loglevel>
      <logsubject>EXTRACT METADATA</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>384</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Allow recreate? </name>
      <description />
      <type>SIMPLE_EVAL</type>
      <attributes />
      <valuetype>variable</valuetype>
      <fieldname />
      <variablename>${ALLOW_RECREATE}</variablename>
      <fieldtype>number</fieldtype>
      <mask />
      <comparevalue>1</comparevalue>
      <minvalue />
      <maxvalue />
      <successcondition>equal</successcondition>
      <successnumbercondition>equal</successnumbercondition>
      <successbooleancondition>false</successbooleancondition>
      <successwhenvarset>N</successwhenvarset>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>720</xloc>
      <yloc>160</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Fail extracting metadata</name>
      <description />
      <type>ABORT</type>
      <attributes />
      <message />
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>608</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Metadata exists? </name>
      <description />
      <type>FILE_EXISTS</type>
      <attributes />
      <filename>${METADATA_COLUMNS_FILE}</filename>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>384</xloc>
      <yloc>496</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Set recreate to 0 </name>
      <description />
      <type>SET_VARIABLES</type>
      <attributes />
      <replacevars>N</replacevars>
      <filename />
      <file_variable_type>ROOT_JOB</file_variable_type>
      <fields>
        <field>
          <variable_name>IS_RECREATE</variable_name>
          <variable_value>0</variable_value>
          <variable_type>ROOT_JOB</variable_type>
        </field>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>608</xloc>
      <yloc>496</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Move to done</name>
      <description />
      <type>SHELL</type>
      <attributes />
      <filename />
      <work_directory />
      <arg_from_previous>N</arg_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <set_append_logfile>N</set_append_logfile>
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <insertScript>Y</insertScript>
      <script>error_check(){
	if [ $? -gt 0 ]; then
       	echo "An error has occurred :_("
		exit 1
	fi
}

if [ "${FILE_DONE_BUCKET}" != "" ]; then
	if [[ "$FILE_DONE_BUCKET" == *"s3://"* ]]; then	
		echo "Saving ${FILE_INPUT_BUCKET} on ${FILE_DONE_BUCKET}"

		aws s3 mv ${FILE_INPUT_BUCKET} ${FILE_DONE_BUCKET} --recursive --only-show-errors
		rm -f ${FILE_INPUT_BUCKET}*
		error_check
	else
		echo "Saving ${FILE_INPUT_BUCKET} on ${FILE_DONE_BUCKET}"
		
		mv ${FILE_INPUT_BUCKET}* ${FILE_DONE_BUCKET}
		error_check
	fi
else 
	echo "Do not have a done bucket!"

	if [[ "$FILE_DONE_BUCKET" != *"s3://"* ]]; then	
		if [ ${DEBUG} = 0 ] ; then
			echo "Cleaning up ${FILE_INPUT_BUCKET}"
			rm -f ${FILE_INPUT_BUCKET}*
		fi
	fi
fi</script>
      <loglevel>Basic</loglevel>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>608</xloc>
      <yloc>608</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Success</name>
      <description />
      <type>SUCCESS</type>
      <attributes />
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>608</xloc>
      <yloc>720</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Get metadata definition</name>
      <description />
      <type>TRANS</type>
      <attributes />
      <specification_method>filename</specification_method>
      <trans_object_id />
      <filename>${Internal.Job.Filename.Directory}/m_load_metadata_definition.ktr</filename>
      <transname />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
        <parameter>
          <name>METADATA_FIELDS_FILE</name>
          <stream_name />
          <value>${METADATA_FIELDS_FILE}</value>
        </parameter>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>832</xloc>
      <yloc>384</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Recreate is not allowed</name>
      <description />
      <type>ABORT</type>
      <attributes />
      <message />
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>720</xloc>
      <yloc>272</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Get files</name>
      <description />
      <type>JOB</type>
      <attributes />
      <specification_method>filename</specification_method>
      <job_object_id />
      <filename>${Internal.Entry.Current.Directory}/j_get_files_from_bucket.kjb</filename>
      <jobname />
      <directory />
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name />
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>256</xloc>
      <yloc>272</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Log</name>
      <description />
      <type>WRITE_TO_LOG</type>
      <attributes />
      <logmessage>#-----------------------------------------------------------
# INPUT
#-----------------------------------------------------------
FILE_INPUT_BUCKET		== ${FILE_INPUT_BUCKET}
FILE_INPUT_DELIMITER		== ${FILE_INPUT_DELIMITER}
METADATA			== ${METADATA}
QUOTE_ESCAPE			== ${QUOTE_ESCAPE}
#-----------------------------------------------------------
# INPUT SAMPLE
#-----------------------------------------------------------
SAMPLE				== ${SAMPLE}
#-----------------------------------------------------------
# OUTPUT
#-----------------------------------------------------------
TARGET				== ${TARGET}
SCHEMA				== ${SCHEMA_NAME}
TABLE_NAME			== ${TABLE_NAME}
STORAGE_BUCKET			== ${STORAGE_BUCKET}
OUTPUT_FORMAT			== ${OUTPUT_FORMAT}
OUTPUT_COMPRESSION		== ${OUTPUT_COMPRESSION}
#-----------------------------------------------------------
# OUTPUT STRATEGY
#-----------------------------------------------------------
FILE_INPUT_PARTITONED		== ${FILE_INPUT_PARTITONED}
FILE_OUTPUT_MODE		== ${FILE_OUTPUT_MODE}
FILE_DONE_BUCKET		== ${FILE_DONE_BUCKET}</logmessage>
      <loglevel>Basic</loglevel>
      <logsubject>LOG</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>272</yloc>
      <attributes_kjc />
    </entry>
  </entries>
  <hops>
    <hop>
      <from>Metadata compare</from>
      <to>Recreate?</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Metadata exists?</from>
      <to>Set recreate to 1</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Set recreate to 1</from>
      <to>Update metadata</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Load data</from>
      <to>Fail loading data</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Recreate?</from>
      <to>Set recreate to 0</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Metadata exists?</from>
      <to>Recreate? </to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Recreate? </from>
      <to>Metadata compare</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Extract metadata</from>
      <to>Metadata exists?</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Recreate? </from>
      <to>Recreate log</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Recreate log</from>
      <to>Update metadata</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Extract metadata</from>
      <to>Metadata log</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Recreate?</from>
      <to>Allow recreate? </to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Allow recreate? </from>
      <to>Recreate log</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Metadata log</from>
      <to>Metadata exists? </to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Metadata exists? </from>
      <to>Fail extracting metadata</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Set recreate to 0 </from>
      <to>Move to done</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Metadata exists? </from>
      <to>Set recreate to 0 </to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Load data</from>
      <to>Set recreate to 0 </to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Move to done</from>
      <to>Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Set recreate to 0</from>
      <to>Get metadata definition</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Get metadata definition</from>
      <to>Load data</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Update metadata</from>
      <to>Get metadata definition</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Allow recreate? </from>
      <to>Recreate is not allowed</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Get files</from>
      <to>Extract metadata</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>Log</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Log</from>
      <to>Get files</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
      <attribute>
        <key>Pentaho local</key>
        <value>{"children":[{"children":[],"id":"server","value":null},{"children":[],"id":"clustered","value":"N"},{"children":[],"id":"name","value":"Pentaho local"},{"children":[],"id":"description","value":null},{"children":[],"id":"pentaho","value":"N"},{"children":[],"id":"readOnly","value":"Y"},{"children":[],"id":"sendResources","value":"N"},{"children":[],"id":"logRemoteExecutionLocally","value":"N"},{"children":[],"id":"remote","value":"N"},{"children":[],"id":"local","value":"Y"},{"children":[],"id":"showTransformations","value":"N"}],"id":"Pentaho local","value":null,"name":"Pentaho local","owner":null,"ownerPermissionsList":[]}</value>
      </attribute>
    </group>
  </attributes>
</job>
